{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzEa8njTzy1K"
      },
      "source": [
        "# Case Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqW0m1AdzCQA"
      },
      "source": [
        "**Note**: This COLAB notebook is for the case study of REINDEER software.\n",
        "\n",
        "**Reference**: Paper is under production.\n",
        "\n",
        "**Package Version** (at the time of creating this notebook - 4/7/2024):\n",
        "\n",
        "* umpy: 1.25.2\n",
        "\n",
        "* pandas: 2.0.3\n",
        "\n",
        "* xgboost: 2.0.3\n",
        "\n",
        "* scipy: 1.11.4\n",
        "\n",
        "* scikit-learn: 1.2.2\n",
        "\n",
        "* optuna: 3.6.1\n",
        "\n",
        "* matplotlib: 3.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eN5L3Rka7TK-"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "import os\n",
        "\n",
        "print(\"Packages are installing...\")\n",
        "os.system(\"pip install -q optuna\")\n",
        "print(\"Optuna is installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RsBtv-M9yWWD"
      },
      "outputs": [],
      "source": [
        "#@title Clone REINDEER Github\n",
        "!git clone --quiet https://github.com/miladrayka/reindeer_software.git\n",
        "print(\"Files are downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bXP_VS2H9c7t"
      },
      "outputs": [],
      "source": [
        "# @title Load packages\n",
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "import scipy\n",
        "import optuna\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "print(\"Package version:\")\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"pandas: {pd.__version__}\")\n",
        "print(f\"xgboost: {xgb.__version__}\")\n",
        "print(f\"scipy: {scipy.__version__}\")\n",
        "print(f\"scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"optuna: {optuna.__version__}\")\n",
        "print(f\"matplotlib: {matplotlib.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6SblqMq-mCy"
      },
      "source": [
        "#1- Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgZM7P6XVaMs"
      },
      "outputs": [],
      "source": [
        "def preprocessing(\n",
        "    fv_path: str,\n",
        "    ba_path: str,\n",
        "    var_threshold: float = 0.01,\n",
        "    corr_threshold: float = 0.95,\n",
        "    val_size: int = 0,\n",
        ") -> dict:\n",
        "    \"\"\"Preprocess features input pd.DataFrame and drop static, quasi-static and\n",
        "    correlated features. Return standardized and processed data in\n",
        "    pd.DataFrame, mean and std of data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fv_path : str\n",
        "        Path to a feature vector csv file.\n",
        "    ba_path: str\n",
        "        Path to the binding affinity csv file.\n",
        "    var_threshold : float, optional\n",
        "        Variance threshold. Features below this\n",
        "        threshold are discarded, by default 0.01\n",
        "    corr_threshold : float, optional\n",
        "        Correlated features are discarded, by default 0.95\n",
        "    val_size: int, optional\n",
        "        Sample a random validation set, by default 0\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    set_split: dict\n",
        "        Return a dictionary containing numpy arrays of train and test (validation) sets.\n",
        "    \"\"\"\n",
        "\n",
        "    fv_df = pd.read_csv(fv_path, index_col=\"pdbid\")\n",
        "    ba_df = pd.read_csv(ba_path, index_col=\"pdbid\").reindex(fv_df.index)\n",
        "\n",
        "    x_train_df = fv_df.loc[ba_df[\"train\"], :]\n",
        "    x_test_df = fv_df.loc[ba_df[\"test\"], :]\n",
        "    y_train_df = ba_df.loc[ba_df[\"train\"], :]\n",
        "    y_test_df = ba_df.loc[ba_df[\"test\"], :]\n",
        "\n",
        "    x_train_df = x_train_df.loc[(x_train_df != 0).any(axis=1)]\n",
        "    x_test_df = x_test_df.loc[(x_test_df != 0).any(axis=1)]\n",
        "    y_train = y_train_df.loc[x_train_df.index, \"binding_affinity\"]\n",
        "    y_test = y_test_df.loc[x_test_df.index, \"binding_affinity\"]\n",
        "\n",
        "    x_train_df = x_train_df.loc[:, x_train_df.var(axis=0) > var_threshold]\n",
        "    corr_matrix = x_train_df.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [\n",
        "        column for column in upper.columns if any(upper[column] > corr_threshold)\n",
        "    ]\n",
        "    x_train_df = x_train_df.drop(to_drop, axis=1)\n",
        "\n",
        "    mean = x_train_df.mean()\n",
        "    std = x_train_df.std()\n",
        "\n",
        "    x_train_df = (x_train_df - mean) / std\n",
        "    x_test_df = (x_test_df.loc[:, x_train_df.columns] - mean) / std\n",
        "\n",
        "    train_test_split = {\n",
        "        \"x_train\": x_train_df.to_numpy(),\n",
        "        \"x_test\": x_test_df.to_numpy(),\n",
        "        \"y_train\": y_train.to_numpy(),\n",
        "        \"y_test\": y_test.to_numpy(),\n",
        "    }\n",
        "\n",
        "    if val_size:\n",
        "        np.random.seed(42)\n",
        "        indexes = np.random.choice(\n",
        "            range(train_test_split[\"x_train\"].shape[0]), val_size, replace=False\n",
        "        )\n",
        "        mask = np.zeros(train_test_split[\"x_train\"].shape[0], dtype=bool)\n",
        "        mask[indexes] = True\n",
        "\n",
        "        train_test_split[\"x_val\"] = train_test_split[\"x_train\"][mask]\n",
        "        train_test_split[\"y_val\"] = train_test_split[\"y_train\"][mask]\n",
        "        train_test_split[\"x_train\"] = train_test_split[\"x_train\"][~mask]\n",
        "        train_test_split[\"y_train\"] = train_test_split[\"y_train\"][~mask]\n",
        "\n",
        "    print(\"Split shapes:\")\n",
        "    for key, value in train_test_split.items():\n",
        "        print(f\"{key}: {value.shape}\")\n",
        "\n",
        "    return train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMk1-wrPS2_H"
      },
      "outputs": [],
      "source": [
        "def config_file(params: str, filename: str) -> None:\n",
        "    \"\"\"Save hyperparameters to a .json file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : dict\n",
        "        hyperparameters of xgboost.XGBREGRESSOR algorithm.\n",
        "    filename : str\n",
        "        Name of the json file.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(filename, \"w\") as file:\n",
        "        json.dump(params, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvWO_hh6O888"
      },
      "outputs": [],
      "source": [
        "class Model(object):\n",
        "    \"\"\"A class for training, validating, and testing of a scoring function.\n",
        "    xgboost.XGBREGRESSOR is used as a learner.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_split: dict, params: dict, num_regressor: int) -> None:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_split : dict\n",
        "            Train, validation, and test sets split from preprocessing function.\n",
        "        params : dict\n",
        "            Hyperparameters of xgboost.XGBREGRESSOR.\n",
        "        num_regressor : int\n",
        "            Number of desired regressors to train.\n",
        "        \"\"\"\n",
        "\n",
        "        self.data_split = data_split\n",
        "        self.random_numbers = np.random.randint(0, 10000, num_regressor)\n",
        "        self.regressors = [\n",
        "            xgb.XGBRegressor(random_state=self.random_numbers[num], **params)\n",
        "            for num in range(num_regressor)\n",
        "        ]\n",
        "        self.results = {}\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"\"\"Train a xgboost.XGBREGRESSOR.\"\"\"\n",
        "        for reg in self.regressors:\n",
        "            reg.fit(self.data_split[\"x_train\"], self.data_split[\"y_train\"])\n",
        "\n",
        "    def eval(self, mode: str) -> None:\n",
        "        \"\"\"Evaluate trained models.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode : str\n",
        "          Evaluate on validation (val) or test sets. Only val and test strings\n",
        "          are allowed.\n",
        "        \"\"\"\n",
        "\n",
        "        assert mode in [\"val\", \"test\"], \"Mode should be val or test\"\n",
        "\n",
        "        self.results[mode] = [\n",
        "            reg.predict(self.data_split[f\"x_{mode}\"]) for reg in self.regressors\n",
        "        ]\n",
        "\n",
        "    def metrics(self, mode: str) -> dict:\n",
        "        \"\"\"Calculate performance of a trained model on validation and test\n",
        "        sets by root-mean-square error (RMSE) and Pearson's correlation\n",
        "        coefficient (RP).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode : str\n",
        "          Calculate performance on validation (val) or test sets. Only val and\n",
        "          test strings are allowed.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            Calculated RMSE and RP for validation or test sets.\n",
        "        \"\"\"\n",
        "\n",
        "        assert mode in [\"val\", \"test\"], \"Mode should be val or test\"\n",
        "\n",
        "        metric_results = defaultdict(list)\n",
        "\n",
        "        for result in self.results[mode]:\n",
        "            rmse_value = sklearn.metrics.mean_squared_error(\n",
        "                result, self.data_split[f\"y_{mode}\"], squared=False\n",
        "            )\n",
        "            rp_value = scipy.stats.pearsonr(result, self.data_split[f\"y_{mode}\"])[0]\n",
        "            metric_results[\"rmse\"].append(rmse_value)\n",
        "            metric_results[\"rp\"].append(rp_value)\n",
        "\n",
        "        return metric_results\n",
        "\n",
        "    def save_model(self, pathfile: str, name: str) -> None:\n",
        "        \"\"\"Save the trained models.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        pathfile : str\n",
        "            A path to save the models.\n",
        "        name : str\n",
        "            A name to save models, e.g., xgb_oic.\n",
        "        \"\"\"\n",
        "\n",
        "        for num, reg in enumerate(self.regressors, start=1):\n",
        "            reg.save_model(os.path.join(pathfile, f\"{name}_{num}.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3zWB7FFeCtz"
      },
      "outputs": [],
      "source": [
        "def objective(trial: object, data_split: dict) -> float:\n",
        "    \"\"\"Objective for hyperparameters optimization by Optuna.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    trial : object\n",
        "        A parameter for Optuna package.\n",
        "    data_split : dict\n",
        "        Train, validation, and test sets split from preprocessing function.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Pearson's correlation coefficient (RP).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"device\": \"cpu\",#cuda:0 for GPU.\n",
        "        \"n_jobs\": -1,\n",
        "        \"tree_method\": \"hist\",\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        \"verbosity\": 0,\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 20000, step=100),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
        "    }\n",
        "\n",
        "    xgb_reg = Model(data_split, params, 1)\n",
        "    xgb_reg.train()\n",
        "\n",
        "    xgb_reg.eval(\"val\")\n",
        "    val_metrics = xgb_reg.metrics(\"val\")\n",
        "    rp_value = val_metrics[\"rp\"][0]\n",
        "\n",
        "    return rp_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGzb0ES_eFj0"
      },
      "outputs": [],
      "source": [
        "def hp_optimize(num_trials: int, data_split: dict) -> tuple:\n",
        "    \"\"\"Optimize hyperparameters by Optuna.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_trials : int\n",
        "        Number of trials to find hyperparameters.\n",
        "    data_split : dict\n",
        "        Train, validation, and test sets split from preprocessing function.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        Tuple of validation performance and best hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    objective_partial = partial(objective, data_split=data_split)\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_partial, n_trials=num_trials)\n",
        "\n",
        "    return (study.best_value, study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6cwo0NvseRX"
      },
      "outputs": [],
      "source": [
        "def save_metrics(val_metrics: dict, test_metrics: dict, filename: str) -> None:\n",
        "    \"\"\"Save validation and test metrics to a .csv file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    val_metrics : dict\n",
        "        Metrics for a validation set.\n",
        "    test_metrics: dict\n",
        "        Metrics for a test set.\n",
        "    filename : str\n",
        "        Name of the csv file.\n",
        "    \"\"\"\n",
        "\n",
        "    df1 = pd.DataFrame(val_metrics).rename({\"rmse\": \"val_rmse\", \"rp\": \"val_rp\"}, axis=1)\n",
        "    df2 = pd.DataFrame(test_metrics).rename(\n",
        "        {\"rmse\": \"test_rmse\", \"rp\": \"test_rp\"}, axis=1\n",
        "    )\n",
        "    pd.concat([df1, df2], axis=1).to_csv(f\"{filename}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlAVeDZVkTIw"
      },
      "outputs": [],
      "source": [
        "def comparison_plot(\n",
        "    heights: list,\n",
        "    labels: list,\n",
        "    colors: list,\n",
        "    title: str,\n",
        "\n",
        "    y_label: str,\n",
        "\n",
        "    y_lim: float,\n",
        "\n",
        "    filename: str,\n",
        ") -> None:\n",
        "\n",
        "    \"\"\"Plot a comparison bar chart.\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    heights: list\n",
        "\n",
        "        A list of values of a metric for test or validation set.\n",
        "    labels: list\n",
        "\n",
        "        A list of labels for x-axis.\n",
        "    colors: list\n",
        "\n",
        "        A list of colors.\n",
        "    title: str\n",
        "\n",
        "        Title of diagram.\n",
        "\n",
        "    y_label: str\n",
        "\n",
        "        Label for y-axis,e.g., RMSE or RP.\n",
        "\n",
        "    y_lim: float\n",
        "\n",
        "      For RMSE set it 2.0 for RP set is 1.0.\n",
        "    filename: str\n",
        "\n",
        "      Name of file to save diagram in .png format with doi=600.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    plt.bar(labels, heights, color=colors, width=0.6, edgecolor=\"black\", linewidth=1.5)\n",
        "\n",
        "    plt.ylim(0, y_lim)\n",
        "\n",
        "    plt.xlabel(\"Scoring Function\", fontsize=12)\n",
        "\n",
        "    plt.ylabel(y_label, fontsize=12)\n",
        "\n",
        "    plt.grid(True, color=\"grey\", linestyle=\"--\", linewidth=0.5)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.savefig(f\"{filename}.png\", dpi=600)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qFHm79t-2Aw"
      },
      "source": [
        "#2- Scoring functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LRmHPWHZBQC8"
      },
      "outputs": [],
      "source": [
        "# @title Assigning paths of all generated features, and bindning_affinity data.\n",
        "oic_path = \"/content/reindeer_software/files/casestudy_oic_fv.csv\"  # @param\n",
        "dwic_path = \"/content/reindeer_software/files/casestudy_dwic_fv.csv\"  # @param\n",
        "ecif_path = \"/content/reindeer_software/files/casestudy_ecif_fv.csv\"  # @param\n",
        "binding_affinity_path = (\n",
        "    \"/content/reindeer_software/files/train_test_labels.csv\"  # @param\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d3qizo5-6Sr"
      },
      "source": [
        "##2-1- OIC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As9sZRcXDDTT"
      },
      "source": [
        "Making scoring function using OIC representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il90b75rAGxw"
      },
      "outputs": [],
      "source": [
        "oic_data_split = preprocessing(\n",
        "    fv_path=oic_path,\n",
        "\n",
        "    ba_path=binding_affinity_path,\n",
        "\n",
        "    var_threshold=0.01,\n",
        "\n",
        "    corr_threshold=0.95,\n",
        "\n",
        "    val_size=300,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTNPJa4sYGAx"
      },
      "outputs": [],
      "source": [
        "_, best_params = hp_optimize(50, oic_data_split)\n",
        "config_file(best_params, \"/content/xgb_oic_hp.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6hnEatiVq_H"
      },
      "outputs": [],
      "source": [
        "xgb_models = Model(oic_data_split, best_params, 5)\n",
        "xgb_models.train()\n",
        "\n",
        "xgb_models.eval(\"val\")\n",
        "val_metrics = xgb_models.metrics(\"val\")\n",
        "xgb_models.eval(\"test\")\n",
        "test_metrics = xgb_models.metrics(\"test\")\n",
        "\n",
        "xgb_models.save_model(\"/content/\", \"xgb_oic\")\n",
        "save_metrics(val_metrics, test_metrics, \"/content/oic_metrics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccYM9h2W5xjT"
      },
      "source": [
        "##2-2- DWIC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-mAvpZM52ML"
      },
      "source": [
        "Making scoring function using DWIC representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjJ7-3hLt0uj"
      },
      "outputs": [],
      "source": [
        "dwic_data_split = preprocessing(\n",
        "    fv_path=dwic_path,\n",
        "\n",
        "    ba_path=binding_affinity_path,\n",
        "\n",
        "    var_threshold=0.01,\n",
        "\n",
        "    corr_threshold=0.95,\n",
        "\n",
        "    val_size=300,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnAnISAKuiyg"
      },
      "outputs": [],
      "source": [
        "_, best_params = hp_optimize(50, dwic_data_split)\n",
        "config_file(best_params, \"/content/xgb_dwic_hp.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIHNPdfO6HHZ"
      },
      "outputs": [],
      "source": [
        "xgb_models = Model(dwic_data_split, best_params, 5)\n",
        "xgb_models.train()\n",
        "\n",
        "xgb_models.eval(\"val\")\n",
        "val_metrics = xgb_models.metrics(\"val\")\n",
        "xgb_models.eval(\"test\")\n",
        "test_metrics = xgb_models.metrics(\"test\")\n",
        "\n",
        "xgb_models.save_model(\"/content/\", \"xgb_dwic\")\n",
        "save_metrics(val_metrics, test_metrics, \"/content/dwic_metrics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovm1l3QnGNHm"
      },
      "source": [
        "##2-3- ECIF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LfdJL1gGU1c"
      },
      "source": [
        "Making scoring function using ECIF representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQCgQTQFGRcD"
      },
      "outputs": [],
      "source": [
        "ecif_data_split = preprocessing(\n",
        "    fv_path=ecif_path,\n",
        "\n",
        "    ba_path=binding_affinity_path,\n",
        "\n",
        "    var_threshold=0.01,\n",
        "\n",
        "    corr_threshold=0.95,\n",
        "\n",
        "    val_size=300,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaZp2I08GdgG"
      },
      "outputs": [],
      "source": [
        "_, best_params = hp_optimize(50, ecif_data_split)\n",
        "config_file(best_params, \"/content/xgb_ecif_hp.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgqc28FSGjk6"
      },
      "outputs": [],
      "source": [
        "xgb_models = Model(ecif_data_split, best_params, 5)\n",
        "xgb_models.train()\n",
        "\n",
        "xgb_models.eval(\"val\")\n",
        "val_metrics = xgb_models.metrics(\"val\")\n",
        "xgb_models.eval(\"test\")\n",
        "test_metrics = xgb_models.metrics(\"test\")\n",
        "\n",
        "xgb_models.save_model(\"/content/\", \"xgb_ecif\")\n",
        "save_metrics(val_metrics, test_metrics, \"/content/ecif_metrics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj-ikrXWbqYe"
      },
      "source": [
        "#3- Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "retbPBJ6ekh6"
      },
      "outputs": [],
      "source": [
        "path = \"/content\"\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for method in [\"oic\", \"dwic\", \"ecif\"]:\n",
        "    df = pd.read_csv(f\"{path}/{method}_metrics.csv\")\n",
        "    df.index = [f\"{method}_{i}\" for i in df.index]\n",
        "    df.loc[f\"{method}_mean\", :] = df.mean()\n",
        "    df.loc[f\"{method}_std\", :] = df.std()\n",
        "    df = df.round(4)\n",
        "    df_list.append(df)\n",
        "\n",
        "pd.concat(df_list, axis=0).to_csv(f\"{path}/all_results.csv\", index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lInLvA-dhWJS"
      },
      "outputs": [],
      "source": [
        "colors = [\n",
        "    \"cyan\",\n",
        "    \"darkturquoise\",\n",
        "    \"cadetblue\",\n",
        "    \"deepskyblue\",\n",
        "    \"steelblue\",\n",
        "    \"dodgerblue\",\n",
        "    \"lighteagreen\",\n",
        "    \"teal\",\n",
        "]\n",
        "\n",
        "labels = [\"OIC\", \"DWIC\", \"ECIF\"]\n",
        "\n",
        "\n",
        "results_df = pd.read_csv(f\"{path}/all_results.csv\", index_col=0)\n",
        "\n",
        "mean_results_df = results_df.iloc[5:-1:7, :]\n",
        "\n",
        "\n",
        "valid_rps = mean_results_df.loc[:, \"val_rp\"].values\n",
        "\n",
        "valid_rmses = mean_results_df.loc[:, \"val_rmse\"].values\n",
        "test_rps = mean_results_df.loc[:, \"test_rp\"].values\n",
        "test_rmses = mean_results_df.loc[:, \"test_rmse\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCPtVK9UlEYE"
      },
      "outputs": [],
      "source": [
        "comparison_plot(\n",
        "    valid_rps,\n",
        "    labels,\n",
        "    colors[:4],\n",
        "    \"Performance on Validation Set\",\n",
        "    \"$R_{P}$\",\n",
        "    1.0,\n",
        "    \"valid_results_rp\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThvQt3LZl0XS"
      },
      "outputs": [],
      "source": [
        "comparison_plot(\n",
        "    valid_rmses,\n",
        "    labels,\n",
        "    colors[:4],\n",
        "    \"Performance on Validation Set\",\n",
        "    \"RMSE\",\n",
        "    2.0,\n",
        "    \"valid_results_rmse\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSMhFj4wmHgy"
      },
      "outputs": [],
      "source": [
        "comparison_plot(\n",
        "    test_rps,\n",
        "    labels,\n",
        "    colors[:4],\n",
        "    \"Performance on Validation Set\",\n",
        "    \"$R_{P}$\",\n",
        "    1.0,\n",
        "    \"test_results_rp\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBdLgXx_mINR"
      },
      "outputs": [],
      "source": [
        "comparison_plot(\n",
        "    test_rmses,\n",
        "    labels,\n",
        "    colors[:4],\n",
        "    \"Performance on Validation Set\",\n",
        "    \"RMSE\",\n",
        "    2.0,\n",
        "    \"test_results_rmse\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVTJDLGlgZXm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wzEa8njTzy1K",
        "y6SblqMq-mCy",
        "6qFHm79t-2Aw",
        "1d3qizo5-6Sr",
        "ccYM9h2W5xjT",
        "Ovm1l3QnGNHm",
        "Aj-ikrXWbqYe"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
